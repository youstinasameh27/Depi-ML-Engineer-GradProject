{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34595,"sourceType":"datasetVersion","datasetId":26922}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/malakalaa2004/data-preprocesion-depi?scriptVersionId=269772645\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y pillow torchvision\n!pip install pillow==9.5.0 torchvision==0.15.2\n!pip install facenet-pytorch\nimport os; os.kill(os.getpid(), 9)  # force restart\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import hashlib\nimport shutil\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torchvision import transforms\nfrom facenet_pytorch import MTCNN\nfrom sklearn.model_selection import train_test_split\nimport os\n\n# Correct dataset root path based on paste.txt\nbase_dir = '/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\nprocessed_dir = '/kaggle/working/processed_faces'\ntrain_dir = '/kaggle/working/data_split/train'\nval_dir = '/kaggle/working/data_split/val'\nval_split = 0.2\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmtcnn = MTCNN(image_size=160, margin=10, min_face_size=10, device=device)\n\naugment = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n])\n\nshutil.rmtree(processed_dir, ignore_errors=True)\nos.makedirs(processed_dir, exist_ok=True)\n\n# Test face detection on sample image to verify correct paths and model working\ndef test_face_detection(image_path):\n    img = Image.open(image_path).convert('RGB')\n    boxes, probs = mtcnn.detect(img)\n    print(f\"Detected boxes for {image_path}: {boxes}\")\n\ntest_face_detection('/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/Aaron_Eckhart/Aaron_Eckhart_0001.jpg')\n\n# Step 1: Detect, crop, align faces, save\ndef save_faces(data_dir, save_dir):\n    image_paths = list(Path(data_dir).rglob('*.jpg'))\n    for img_path in tqdm(image_paths, desc=\"Processing images\"):\n        person_name = img_path.parent.name\n        save_person_dir = Path(save_dir) / person_name\n        save_person_dir.mkdir(parents=True, exist_ok=True)\n        try:\n            img = Image.open(img_path).convert('RGB')\n            face = mtcnn(img)\n            if face is not None:\n                face_img = transforms.ToPILImage()(face)\n                dst_path = save_person_dir / img_path.name\n                face_img.save(dst_path)\n                print(f\"Saved face to {dst_path}\")\n            else:\n                print(f\"No face detected in {img_path}\")\n        except Exception as e:\n            print(f\"Error processing {img_path}: {e}\")\n            continue\n\nsave_faces(base_dir, processed_dir)\n\nnum_processed = sum(1 for _ in Path(processed_dir).rglob('*.jpg'))\nprint(f\"Number of processed face images: {num_processed}\")\n\n# Step 2: Augmentation\ndef augment_faces(src_dir, num_aug=2):\n    for person_dir in Path(src_dir).iterdir():\n        for img_path in person_dir.glob('*.jpg'):\n            img = Image.open(img_path)\n            for i in range(num_aug):\n                img_aug = augment(img)\n                save_aug_dir = Path(src_dir) / person_dir.name\n                save_aug_dir.mkdir(parents=True, exist_ok=True)\n                img_aug.save(save_aug_dir / f\"{img_path.stem}_aug{i}{img_path.suffix}\")\n\naugment_faces(processed_dir)\n\n# Step 3: Remove duplicates\ndef remove_duplicates(folder):\n    seen_hashes = set()\n    num_removed = 0\n    for person_dir in Path(folder).iterdir():\n        if not person_dir.is_dir():\n            continue\n        for img_path in list(person_dir.glob('*.jpg')):\n            with open(img_path, 'rb') as f:\n                filehash = hashlib.md5(f.read()).hexdigest()\n            if filehash in seen_hashes:\n                img_path.unlink()\n                num_removed += 1\n            else:\n                seen_hashes.add(filehash)\n    print(f\"Removed {num_removed} duplicate images.\")\n\nremove_duplicates(processed_dir)\n\n# Step 4: Train/val split\ndef split_train_val(src_dir, train_dir, val_dir, val_split=0.2):\n    for person_dir in Path(src_dir).iterdir():\n        img_paths = list(person_dir.glob('*.jpg'))\n        if len(img_paths) < 2:\n            continue\n        train_imgs, val_imgs = train_test_split(img_paths, test_size=val_split, random_state=42)\n        for t in train_imgs:\n            out_dir = Path(train_dir) / person_dir.name\n            out_dir.mkdir(parents=True, exist_ok=True)\n            shutil.copy(t, out_dir / t.name)\n        for v in val_imgs:\n            out_dir = Path(val_dir) / person_dir.name\n            out_dir.mkdir(parents=True, exist_ok=True)\n            shutil.copy(v, out_dir / v.name)\n\nsplit_train_val(processed_dir, train_dir, val_dir, val_split)\n\nprint(\"Clean and structured dataset ready for training.\")\nprint(f\"Train images in {train_dir}\")\nprint(f\"Validation images in {val_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T18:11:01.494761Z","iopub.execute_input":"2025-10-21T18:11:01.495072Z","iopub.status.idle":"2025-10-21T18:33:28.422128Z","shell.execute_reply.started":"2025-10-21T18:11:01.49505Z","shell.execute_reply":"2025-10-21T18:33:28.421307Z"}},"outputs":[],"execution_count":null}]}